axis.ticks.length = unit(-0.1, "cm"))
gg_specStimNorm
plot(merged_spectally$TaskMean, merged_spectally$Task1)
#### 1 Time steps ####
# Normalize and Summarise by "day" (i.e., time window) and calculate difference
tallyFluct <- tallies %>%
mutate(Task1 = Task1 / n,
Task2 = Task2 / n,
Inactive = Inactive / n,
Set = paste0(n, "-", replicate),
Window = t %/% 1) %>%
group_by(n, Set, Window) %>%
summarise(Task1 = mean(Task1),
Task2 = mean(Task2),
Inactive = mean(Inactive)) %>%
mutate(Task1Diff = abs(Task1 - lag(Task1)),
Task2Diff = abs(Task2 - lag(Task2)),
InactiveDiff = abs(Inactive - lag(Inactive)),
BeginSet = !duplicated(Set))
# Make sure first diff row of each new set is NA
sets <- which(tallyFluct$BeginSet == TRUE)
tallyFluct$Task1Diff[sets] <- NA
tallyFluct$Task2Diff[sets] <- NA
tallyFluct$InactiveDiff[sets] <- NA
# Summarise by colony/set
tallyFluct <- tallyFluct %>%
group_by(n, Set) %>%
summarise(Task1Fluct = mean(Task1Diff, na.rm = TRUE),
Task2Fluct = mean(Task2Diff, na.rm = TRUE),
InactiveFluct = mean(InactiveDiff, na.rm = TRUE)) %>%
mutate(GroupSizeFactor = factor(n, levels = sort(unique(n))))
# Within group - short term flucatuations vs specialization
# Load specialization
taskCorrTot <- do.call("rbind", groups_taskCorr)
taskCorrTot <- taskCorrTot %>%
mutate(TaskMean = (Task1 + Task2) / 2)
taskCorrTot <- taskCorrTot %>%
mutate(Set = paste0(n, "-", replicate)) %>%
select(n, TaskMean, Task1, Task2, Set)
# Merge
merged_spectally <- merge(taskCorrTot, tallyFluct, by = c("Set", "n"))
merged_spectally <- merged_spectally %>%
group_by(n) %>%
mutate(Task1Min = min(Task1Fluct),
Task1Max = max(Task1Fluct),
Task2Min = min(Task2Fluct),
Task2Max = max(Task2Fluct),
TaskMeanMin = min(TaskMean),
TaskMeanMax = max(TaskMean)) %>%
mutate(Task1Norm = (Task1Fluct - Task1Min) / (Task1Max - Task1Min),
Task2Norm = (Task2Fluct - Task2Min) / (Task2Max - Task2Min),
TaskMeanNorm = (TaskMean - TaskMeanMin) / (TaskMeanMax - TaskMeanMin))
plot(merged_spectally$TaskMean, merged_spectally$Task1)
View(merged_spectally)
plot(merged_spectally$TaskMean, merged_spectally$Task1Fluct)
# Merge
merged_spectally <- merge(taskCorrTot, tallyFluct, by = c("Set", "n"))
merged_spectally <- merged_spectally %>%
group_by(n) %>%
mutate(Task1Min = min(Task1Fluct),
Task1Max = max(Task1Fluct),
Task2Min = min(Task2Fluct),
Task2Max = max(Task2Fluct),
TaskMeanMin = min(TaskMean),
TaskMeanMax = max(TaskMean)) %>%
mutate(Task1Norm = (Task1Fluct - Task1Min) / (Task1Max - Task1Min),
Task2Norm = (Task2Fluct - Task2Min) / (Task2Max - Task2Min),
TaskMeanNorm = (TaskMean - TaskMeanMin) / (TaskMeanMax - TaskMeanMin))
gg_specTallyNorm <- ggplot(data = merged_spectally) +
geom_point(aes(x = TaskMeanNorm,
colour = as.factor(n),
y = Task1Norm),
# colour = "#F23619",
size = 0.1) +
theme_classic() +
theme(legend.position = "none") +
ylab("Normalized task fluctuation") +
xlab("Normalized specialization") +
scale_y_continuous(breaks = seq(0, 1, 0.2),
limits = c(-0.01, 1.01),
expand = c(0, 0)) +
scale_x_continuous(breaks = seq(0, 1, 0.2),
limits = c(-0.01, 1.01),
expand = c(0, 0)) +
scale_color_manual(values = palette) +
theme(legend.position = "none",
legend.justification = c(1, 1),
legend.title = element_blank(),
legend.key.height = unit(0.3, "cm"),
legend.key.width= unit(0.4, "cm"),
legend.margin =  margin(t = 0, r = 0, b = 0, l = -0.2, "cm"),
legend.text = element_text(size = 6),
legend.text.align = 0,
# legend.box.background = element_rect(),
axis.text.y = element_text(size = 8, margin = margin(5, 6, 5, -2), color = "black"),
axis.text.x = element_text(size = 8, margin = margin(6, 5, -2, 5), color = "black"),
axis.title = element_text(size = 8, margin = margin(0, 0, 0, 0)),
axis.ticks.length = unit(-0.1, "cm"))
gg_specTallyNorm
ggsave(filename = "output/FitnessPlots/TaskFluctVsSpecializationWithinGroups.png", height = 2, width = 2, dpi = 600)
summary(lm(Task1Norm ~ TaskMeanNOrm, data = merged_spectally))
summary(lm(Task1Norm ~ TaskMeanNorm, data = merged_spectally))
rm(list = ls())
source("scripts/__Util__MASTER.R")
source("scripts/3_PrepPlotExperimentData.R")
library(RColorBrewer)
library(scales)
# Deterministic
load("output/__RData/MSrevision_FixedDelta06_DetThreshDetUpdateDetQuit100reps.Rdata")
individualVar <- lapply(groups_taskOverTime, function(group_size) {
# Loop through replicates within group size
within_groupTaskDiversity <- lapply(group_size, function(replicate) {
# Standard Dev
Variation <- apply(replicate, 1, FUN = sd)
# Shannon's diversity index of tasks
Shannon <- apply(replicate, 1, FUN = function(row) {
inactive <- sum(row == 0) /length(row)
task1 <- sum(row == 1) / length(row)
task2 <- sum(row == 2) / length(row)
entropies <- lapply(c(inactive, task1, task2), function(p) {
E <- p * log(p)
})
entropies[is.na(entropies)] <- 0
diversity <- -1 * sum(unlist(entropies))
})
to_return <- data.frame(n = ncol(replicate),
SD = mean(Variation),
Diversity = mean(Shannon))
return(to_return)
})
group_var <- do.call("rbind", within_groupTaskDiversity)
})
rm(list = ls())
source("scripts/__Util__MASTER.R")
source("scripts/3_PrepPlotExperimentData.R")
library(RColorBrewer)
library(scales)
# Entirely Deterministic
load("output/__RData/MSrevision_FixedDelta06_DetThreshDetUpdateDetQuit100reps.Rdata")
noTaskPerf <- lapply(groups_taskTally, function(group_size) {
# Loop through replicates within group size
within_groupTaskPerf <- lapply(group_size, function(replicate) {
# Get basics and counts of instances in which there isn't anyone performing task
to_return <- data.frame(n = unique(replicate$n),
replicate = unique(replicate$replicate),
Set = paste0(unique(replicate$n), "-", unique(replicate$replicate)),
noTask1 = sum(replicate$Task1 == 0),
noTask2 = sum(replicate$Task2 == 0))
#  Quantify length of no-performance bouts
for (task in c("Task1", "Task2")) {
bout_lengths <- rle(replicate[ , task])
bout_lengths <- as.data.frame(do.call("cbind", bout_lengths))
bout_lengths <- bout_lengths %>%
filter(values == 0)
avg_nonPerformance <- mean(bout_lengths$lengths)
if(task == "Task1") {
to_return$noTask1Length = avg_nonPerformance
}
else {
to_return$noTask2Length = avg_nonPerformance
}
}
# Get averages
to_return <- to_return %>%
mutate(noTaskAvg = (noTask1 + noTask2) / 2,
noTaskLengthAvg = (noTask1Length + noTask2Length) / 2)
# Return
return(to_return)
})
# Bind and return
within_groupTaskPerf <- do.call("rbind", within_groupTaskPerf)
return(within_groupTaskPerf)
})
# Bind
noTaskPerf <- do.call("rbind", noTaskPerf)
noTaskPerf <- noTaskPerf %>%
group_by(n) %>%
mutate(noTask1 = noTask1 / 10000,
noTask2 = noTask2 / 10000,
noTaskAvg = noTaskAvg / 10000) %>%
summarise(TaskNegelectMean = mean(noTaskAvg, na.rm = TRUE),
TaskNegelectSE = ( sd(noTaskAvg) / sqrt(length(noTaskAvg)) )) %>%
mutate(Source = "Deterministic")
taskNeglect_all <- noTaskPerf
# Probabilistic thresholds
load("output/__RData/MSrevision_FixedDelta06_DetUpdateDetQuit100reps.Rdata")
noTaskPerf <- lapply(groups_taskTally, function(group_size) {
# Loop through replicates within group size
within_groupTaskPerf <- lapply(group_size, function(replicate) {
# Get basics and counts of instances in which there isn't anyone performing task
to_return <- data.frame(n = unique(replicate$n),
replicate = unique(replicate$replicate),
Set = paste0(unique(replicate$n), "-", unique(replicate$replicate)),
noTask1 = sum(replicate$Task1 == 0),
noTask2 = sum(replicate$Task2 == 0))
#  Quantify length of no-performance bouts
for (task in c("Task1", "Task2")) {
bout_lengths <- rle(replicate[ , task])
bout_lengths <- as.data.frame(do.call("cbind", bout_lengths))
bout_lengths <- bout_lengths %>%
filter(values == 0)
avg_nonPerformance <- mean(bout_lengths$lengths)
if(task == "Task1") {
to_return$noTask1Length = avg_nonPerformance
}
else {
to_return$noTask2Length = avg_nonPerformance
}
}
# Get averages
to_return <- to_return %>%
mutate(noTaskAvg = (noTask1 + noTask2) / 2,
noTaskLengthAvg = (noTask1Length + noTask2Length) / 2)
# Return
return(to_return)
})
# Bind and return
within_groupTaskPerf <- do.call("rbind", within_groupTaskPerf)
return(within_groupTaskPerf)
})
# Bind
noTaskPerf <- do.call("rbind", noTaskPerf)
noTaskPerf <- noTaskPerf %>%
group_by(n) %>%
mutate(noTask1 = noTask1 / 10000,
noTask2 = noTask2 / 10000,
noTaskAvg = noTaskAvg / 10000) %>%
summarise(TaskNegelectMean = mean(noTaskAvg, na.rm = TRUE),
TaskNegelectSE = ( sd(noTaskAvg) / sqrt(length(noTaskAvg)) )) %>%
mutate(Source = "Prob. Thresholds")
taskNeglect_all <- rbind(taskNeglect_all, noTaskPerf)
# Probabilistic quitting
load("output/__RData/MSrevision_FixedDelta06_DetThreshDetUpdate100reps.Rdata")
noTaskPerf <- lapply(groups_taskTally, function(group_size) {
# Loop through replicates within group size
within_groupTaskPerf <- lapply(group_size, function(replicate) {
# Get basics and counts of instances in which there isn't anyone performing task
to_return <- data.frame(n = unique(replicate$n),
replicate = unique(replicate$replicate),
Set = paste0(unique(replicate$n), "-", unique(replicate$replicate)),
noTask1 = sum(replicate$Task1 == 0),
noTask2 = sum(replicate$Task2 == 0))
#  Quantify length of no-performance bouts
for (task in c("Task1", "Task2")) {
bout_lengths <- rle(replicate[ , task])
bout_lengths <- as.data.frame(do.call("cbind", bout_lengths))
bout_lengths <- bout_lengths %>%
filter(values == 0)
avg_nonPerformance <- mean(bout_lengths$lengths)
if(task == "Task1") {
to_return$noTask1Length = avg_nonPerformance
}
else {
to_return$noTask2Length = avg_nonPerformance
}
}
# Get averages
to_return <- to_return %>%
mutate(noTaskAvg = (noTask1 + noTask2) / 2,
noTaskLengthAvg = (noTask1Length + noTask2Length) / 2)
# Return
return(to_return)
})
# Bind and return
within_groupTaskPerf <- do.call("rbind", within_groupTaskPerf)
return(within_groupTaskPerf)
})
# Bind
noTaskPerf <- do.call("rbind", noTaskPerf)
noTaskPerf <- noTaskPerf %>%
group_by(n) %>%
mutate(noTask1 = noTask1 / 10000,
noTask2 = noTask2 / 10000,
noTaskAvg = noTaskAvg / 10000) %>%
summarise(TaskNegelectMean = mean(noTaskAvg, na.rm = TRUE),
TaskNegelectSE = ( sd(noTaskAvg) / sqrt(length(noTaskAvg)) )) %>%
mutate(Source = "Prob. Quitting")
taskNeglect_all <- rbind(taskNeglect_all, noTaskPerf)
# Probabilistic Updating
load("output/__RData/MSrevision_FixedDelta06_DetThreshDetQuit100reps.Rdata")
noTaskPerf <- lapply(groups_taskTally, function(group_size) {
# Loop through replicates within group size
within_groupTaskPerf <- lapply(group_size, function(replicate) {
# Get basics and counts of instances in which there isn't anyone performing task
to_return <- data.frame(n = unique(replicate$n),
replicate = unique(replicate$replicate),
Set = paste0(unique(replicate$n), "-", unique(replicate$replicate)),
noTask1 = sum(replicate$Task1 == 0),
noTask2 = sum(replicate$Task2 == 0))
#  Quantify length of no-performance bouts
for (task in c("Task1", "Task2")) {
bout_lengths <- rle(replicate[ , task])
bout_lengths <- as.data.frame(do.call("cbind", bout_lengths))
bout_lengths <- bout_lengths %>%
filter(values == 0)
avg_nonPerformance <- mean(bout_lengths$lengths)
if(task == "Task1") {
to_return$noTask1Length = avg_nonPerformance
}
else {
to_return$noTask2Length = avg_nonPerformance
}
}
# Get averages
to_return <- to_return %>%
mutate(noTaskAvg = (noTask1 + noTask2) / 2,
noTaskLengthAvg = (noTask1Length + noTask2Length) / 2)
# Return
return(to_return)
})
# Bind and return
within_groupTaskPerf <- do.call("rbind", within_groupTaskPerf)
return(within_groupTaskPerf)
})
# Bind
noTaskPerf <- do.call("rbind", noTaskPerf)
noTaskPerf <- noTaskPerf %>%
group_by(n) %>%
mutate(noTask1 = noTask1 / 10000,
noTask2 = noTask2 / 10000,
noTaskAvg = noTaskAvg / 10000) %>%
summarise(TaskNegelectMean = mean(noTaskAvg, na.rm = TRUE),
TaskNegelectSE = ( sd(noTaskAvg) / sqrt(length(noTaskAvg)) )) %>%
mutate(Source = "Prob. Updating")
taskNeglect_all <- rbind(taskNeglect_all, noTaskPerf)
# Threshold Variation
load("output/__RData/MSrevision_FixedDelta06_DetThreshWithSigmaDetUpdateDetQuit100reps.Rdata")
noTaskPerf <- lapply(groups_taskTally, function(group_size) {
# Loop through replicates within group size
within_groupTaskPerf <- lapply(group_size, function(replicate) {
# Get basics and counts of instances in which there isn't anyone performing task
to_return <- data.frame(n = unique(replicate$n),
replicate = unique(replicate$replicate),
Set = paste0(unique(replicate$n), "-", unique(replicate$replicate)),
noTask1 = sum(replicate$Task1 == 0),
noTask2 = sum(replicate$Task2 == 0))
#  Quantify length of no-performance bouts
for (task in c("Task1", "Task2")) {
bout_lengths <- rle(replicate[ , task])
bout_lengths <- as.data.frame(do.call("cbind", bout_lengths))
bout_lengths <- bout_lengths %>%
filter(values == 0)
avg_nonPerformance <- mean(bout_lengths$lengths)
if(task == "Task1") {
to_return$noTask1Length = avg_nonPerformance
}
else {
to_return$noTask2Length = avg_nonPerformance
}
}
# Get averages
to_return <- to_return %>%
mutate(noTaskAvg = (noTask1 + noTask2) / 2,
noTaskLengthAvg = (noTask1Length + noTask2Length) / 2)
# Return
return(to_return)
})
# Bind and return
within_groupTaskPerf <- do.call("rbind", within_groupTaskPerf)
return(within_groupTaskPerf)
})
# Bind
noTaskPerf <- do.call("rbind", noTaskPerf)
noTaskPerf <- noTaskPerf %>%
group_by(n) %>%
mutate(noTask1 = noTask1 / 10000,
noTask2 = noTask2 / 10000,
noTaskAvg = noTaskAvg / 10000) %>%
summarise(TaskNegelectMean = mean(noTaskAvg, na.rm = TRUE),
TaskNegelectSE = ( sd(noTaskAvg) / sqrt(length(noTaskAvg)) )) %>%
mutate(Source = "Threshold Variation")
taskNeglect_all <- rbind(taskNeglect_all, noTaskPerf)
# Original model
load("output/__RData/FixedDelta06Sigma01Eta7100reps.Rdata")
noTaskPerf <- lapply(groups_taskTally, function(group_size) {
# Loop through replicates within group size
within_groupTaskPerf <- lapply(group_size, function(replicate) {
# Get basics and counts of instances in which there isn't anyone performing task
to_return <- data.frame(n = unique(replicate$n),
replicate = unique(replicate$replicate),
Set = paste0(unique(replicate$n), "-", unique(replicate$replicate)),
noTask1 = sum(replicate$Task1 == 0),
noTask2 = sum(replicate$Task2 == 0))
#  Quantify length of no-performance bouts
for (task in c("Task1", "Task2")) {
bout_lengths <- rle(replicate[ , task])
bout_lengths <- as.data.frame(do.call("cbind", bout_lengths))
bout_lengths <- bout_lengths %>%
filter(values == 0)
avg_nonPerformance <- mean(bout_lengths$lengths)
if(task == "Task1") {
to_return$noTask1Length = avg_nonPerformance
}
else {
to_return$noTask2Length = avg_nonPerformance
}
}
# Get averages
to_return <- to_return %>%
mutate(noTaskAvg = (noTask1 + noTask2) / 2,
noTaskLengthAvg = (noTask1Length + noTask2Length) / 2)
# Return
return(to_return)
})
# Bind and return
within_groupTaskPerf <- do.call("rbind", within_groupTaskPerf)
return(within_groupTaskPerf)
})
# Bind
noTaskPerf <- do.call("rbind", noTaskPerf)
noTaskPerf <- noTaskPerf %>%
group_by(n) %>%
mutate(noTask1 = noTask1 / 10000,
noTask2 = noTask2 / 10000,
noTaskAvg = noTaskAvg / 10000) %>%
summarise(TaskNegelectMean = mean(noTaskAvg, na.rm = TRUE),
TaskNegelectSE = ( sd(noTaskAvg) / sqrt(length(noTaskAvg)) )) %>%
mutate(Source = "Full Model")
taskNeglect_all <- rbind(taskNeglect_all, noTaskPerf)
taskNeglect_all$Source <- factor(taskNeglect_all$Source, levels = c("Deterministic",
"Prob. Updating",
"Prob. Quitting",
"Prob. Thresholds",
"Threshold Variation",
"Full Model"))
# Plot all
gg_models <- ggplot(data = stimFluct_all) +
geom_line(aes(x = n, y = sFluctMean, colour = Source)) +
geom_errorbar(aes(x = n, ymin = sFluctMean - sFluctSE, ymax = sFluctMean + sFluctSE, colour = Source),
width = 1) +
geom_point(aes(x = n, y = sFluctMean, colour = Source),
size = 1.5) +
theme_classic() +
scale_color_brewer(palette = "Set2") +
scale_x_continuous(breaks = unique(stimFluct_all$n)) +
scale_y_continuous(expand = c(0, 0), limits = c(0, 0.95), breaks = seq(0, 1, 0.2)) +
xlab("Group size") +
ylab("Stimulus fluctuation") +
theme(legend.position = "right",
legend.justification = c(1, 1),
legend.title = element_blank(),
legend.key.height = unit(0.3, "cm"),
legend.key.width= unit(0.4, "cm"),
legend.margin =  margin(t = 0, r = 0, b = 0, l = -0.2, "cm"),
legend.text = element_text(size = 8),
legend.text.align = 0,
# legend.box.background = element_rect(),
axis.text.y = element_text(size = 8, margin = margin(5, 6, 5, -2), color = "black"),
axis.text.x = element_text(size = 8, margin = margin(6, 5, -2, 5), color = "black"),
axis.title = element_text(size = 2, margin = margin(0, 0, 0, 0)),
axis.ticks.length = unit(-0.1, "cm"),
aspect.ratio = 1)
gg_models
# Plot all
gg_models <- ggplot(data = taskNeglect_all) +
geom_line(aes(x = n, y = TaskNegelectMean, colour = Source)) +
geom_errorbar(aes(x = n, ymin = TaskNegelectMean - TaskNegelectSE, ymax = TaskNegelectMean + TaskNegelectSE, colour = Source),
width = 1) +
geom_point(aes(x = n, y = TaskNegelectMean, colour = Source),
size = 1.5) +
theme_classic() +
scale_color_brewer(palette = "Set2") +
scale_x_continuous(breaks = unique(taskNeglect_all$n)) +
scale_y_continuous(expand = c(0, 0), limits = c(0, 0.8)) +
xlab("Group size") +
ylab("Task negelect") +
theme(legend.position = "none",
legend.justification = c(1, 1),
legend.title = element_blank(),
legend.key.height = unit(0.3, "cm"),
legend.key.width= unit(0.4, "cm"),
legend.margin =  margin(t = 0, r = 0, b = 0, l = -0.2, "cm"),
legend.text = element_text(size = 10),
legend.text.align = 0,
# legend.box.background = element_rect(),
axis.text.y = element_text(size = 8, margin = margin(5, 6, 5, -2), color = "black"),
axis.text.x = element_text(size = 8, margin = margin(6, 5, -2, 5), color = "black"),
axis.title = element_text(size = 10, margin = margin(0, 0, 0, 0)),
axis.ticks.length = unit(-0.1, "cm"),
aspect.ratio = 1)
gg_models
ggsave("output/StochasticElements/TaskNeglectByModelType.png", width = 2, height = 2, dpi = 600, unit = "in")
source('~/Documents/Research/Tarnita Lab/Incipient Groups DOL/DOLThresholdModel/scripts/other_scripts/ComparingStimFluctuations.R', echo=TRUE)
# Plot all
gg_models <- ggplot(data = stimFluct_all) +
geom_line(aes(x = n, y = sFluctMean, colour = Source)) +
geom_errorbar(aes(x = n, ymin = sFluctMean - sFluctSE, ymax = sFluctMean + sFluctSE, colour = Source),
width = 1) +
geom_point(aes(x = n, y = sFluctMean, colour = Source),
size = 1.5) +
theme_classic() +
scale_color_brewer(palette = "Set2") +
scale_x_continuous(breaks = unique(stimFluct_all$n)) +
scale_y_continuous(expand = c(0, 0), limits = c(0, 0.95), breaks = seq(0, 1, 0.2)) +
xlab("Group size") +
ylab("Stimulus fluctuation") +
theme(legend.position = "none",
legend.justification = c(1, 1),
legend.title = element_blank(),
legend.key.height = unit(0.3, "cm"),
legend.key.width= unit(0.4, "cm"),
legend.margin =  margin(t = 0, r = 0, b = 0, l = -0.2, "cm"),
legend.text = element_text(size = 8),
legend.text.align = 0,
# legend.box.background = element_rect(),
axis.text.y = element_text(size = 8, margin = margin(5, 6, 5, -2), color = "black"),
axis.text.x = element_text(size = 8, margin = margin(6, 5, -2, 5), color = "black"),
axis.title = element_text(size = 10, margin = margin(0, 0, 0, 0)),
axis.ticks.length = unit(-0.1, "cm"),
aspect.ratio = 1)
gg_models
ggsave("output/StochasticElements/StimFluctByModelType.png", width = 2, height = 2, dpi = 600, unit = "in")
