n = n)
# shift down delta (rate increases)
stimMat[t + 1, j + m] <- stimMat[t, j + m]
}
# Update social network
# g_adj <- temporalNetwork(X_sub_g = X_g,
#                          p = p,
#                          bias = q)
# Calculate task demand based on global stimuli
P_g <- calcThresholdProbMat(TimeStep = t + 1, # first row is generation 0
ThresholdMatrix = threshMat,
StimulusMatrix = stimMat,
nSlope = threshSlope)
# Update task performance
X_g <- updateTaskPerformance(P_sub_g    = P_g,
TaskMat    = X_g,
QuitProb   = quitP)
# Capture current task performance tally
tally <- matrix(c(t, colSums(X_g)), ncol = ncol(X_g) + 1)
colnames(tally) <- c("t", colnames(X_g))
tally <- transform(tally, Inactive = n - sum(X_g), n = n, replicate = sim)
taskTally[[t]] <- tally
# Update total task performance profile
X_tot <- X_tot + X_g
# Create time step for correlation
if (t %% corrStep == 0) {
# Get tasks performance in correlation step
X_step <- X_tot - X_prevTot
# Add to ensemble list of task steps
taskStep[[t / corrStep]] <- X_step
# Calculate rank correlation if it is not the first step
if(sum(X_prev) != 0) {
# Normalize
stepNorm <- X_step / rowSums(X_step)
prevNorm <- X_prev / rowSums(X_prev)
# Calculate ranks
step_ranks <- calculateTaskRank(TaskStepMat = X_step)
prev_ranks <- calculateTaskRank(TaskStepMat = X_prev)
# Calculate Correlation
rankCorr <- cor(prev_ranks, step_ranks, method = "spearman")
# Put in list
corr <- diag(rankCorr)
corr <- as.data.frame(corr)
corr <- t(corr)
corr$timestep <- t
corr$n <- n
corr$replicate <- sim
names(corr)[1:2] <- c("Task1", "Task2")
taskCorr <- rbind(taskCorr, corr)
}
# Update previous step total matrix
X_prevTot <- X_tot
# Update previous step total matrix
X_prev <- X_step
}
}
# Calculate Entropy
entropy <- mutualEntropy(TotalStateMat = X_tot)
entropy <- transform(entropy, n = n, replicate = sim)
# Calculate total task distribution
# totalTaskDist <- X_tot / rowSums(X_tot)
totalTaskDist <- X_tot / gens
totalTaskDist <- transform(totalTaskDist, Inactive = gens - rowSums(X_tot), n = n, replicate = sim)
# Create tasktally table
taskTally <- do.call("rbind", taskTally)
# Create tasktally table
stimMat <- transform(stimMat, n = n, replicate = sim)
# Add total task distributions, entropy values, and graphs to lists
ens_taskDist[[sim]]  <- totalTaskDist
ens_entropy[[sim]]   <- entropy
ens_taskCorr[[sim]]  <- taskCorr
ens_taskTally[[sim]] <- taskTally
ens_taskStep[[sim]]  <- taskStep
ens_stim[[sim]]      <- stimMat
# Print simulation completed
print(paste0("DONE: N = ", n, ", Simulation ", sim))
}
# Unlist for corr over time
runCorrs <- do.call("rbind", ens_taskCorr)
# Add to list of lists
groups_taskDist[[i]]  <- ens_taskDist
groups_taskCorr[[i]]  <- runCorrs
groups_taskStep[[i]]  <- ens_taskStep
groups_taskTally[[i]] <- ens_taskTally
groups_stim[[i]]      <- ens_stim
groups_entropy[[i]]   <- ens_entropy
}
rm(list = ls())
source("scripts/__Util__MASTER.R")
####################
# Set global variables
####################
# Initial paramters: Free to change
# Base parameters
Ns             <- c(2, 4, 6, 8, 12, 16, 32, 100) #vector of number of individuals to simulate
m              <- 2 #number of tasks
gens           <- 10000 #number of generations to run simulation
corrStep       <- 200 #number of time steps for calculation of correlation
reps           <- 20 #number of replications per simulation (for ensemble) !!Change!!
# Threshold Parameters
ThreshM        <- c(10, 10) #population threshold means
ThreshSD       <- ThreshM * 0.1 #population threshold standard deviations !!Change!!
InitialStim    <- c(0, 0) #intital vector of stimuli
StimRates      <- c(0.6, 0.6) #vector of stimuli increase rates
threshSlope    <- 7 #exponent parameter for threshold curve shape
alpha          <- m #efficiency of task performance
quitP          <- 0.2 #probability of quitting task once active
# Social Network Parameters
p              <- 0 #probability of interacting with individual in other states
q              <- 1 #probability of interacting with individual in same state relative to others
####################
# Run simulation multiple times
####################
# Prep meta-lists for collection of group size simulations
groups_taskDist  <- list()
groups_taskCorr  <- list()
groups_taskStep  <- list()
groups_taskTally <- list()
groups_stim      <- list()
groups_entropy   <- list()
# Loop through group sizes
for (i in 1:length(Ns)) {
# Set group size
n <- Ns[i]
# Prep lists for collection of simulation outputs
ens_taskDist  <- list()
ens_taskCorr  <- list()
ens_taskStep  <- list()
ens_taskTally <- list()
ens_entropy   <- list()
ens_stim      <- list()
# Run Simulations
for (sim in 1:reps) {
####################
# Seed structures and intial matrices
####################
# Set initial probability matrix (P_g)
P_g <- initiateProbMatrix(n = n, m = m)
# Seed task (external) stimuli
stimMat <- seedStimuls(InitialSVector = InitialStim,
RateVector = StimRates,
gens = gens)
# Seed internal thresholds
threshMat <- seedThresholds(n = n,
m = m,
ThresholdMeans = ThreshM,
ThresholdSDs = ThreshSD)
# Start task performance
X_g <- matrix(data = rep(0, length(P_g)), ncol = ncol(P_g))
# Create cumulative task performance matrix
X_tot <- X_g
# Prep correlation step matrix
X_prev <- matrix(data = rep(0, n * m), ncol = m)
X_prevTot <- matrix(data = rep(0, n * m), ncol = m)
taskCorr <- data.frame(Task1 = NULL, Task2 = NULL, timestep = NULL, n = NULL, replicate = NULL)
taskStep <- list()
taskTally <- list()
####################
# Simulate
####################
# Run simulation
for (t in 1:gens) {
# Update stimuli
for (j in 1:(ncol(stimMat)/2)) {
# update stim
stimMat[t + 1, j] <- globalStimUpdate(stimulus = stimMat[t, j],
delta = stimMat[t, j + m],
alpha = alpha,
Ni = sum(X_g[ , j]),
n = n)
# shift down delta (rate increases)
stimMat[t + 1, j + m] <- stimMat[t, j + m]
}
# Update social network
# g_adj <- temporalNetwork(X_sub_g = X_g,
#                          p = p,
#                          bias = q)
# Calculate task demand based on global stimuli
P_g <- calcThresholdProbMat(TimeStep = t + 1, # first row is generation 0
ThresholdMatrix = threshMat,
StimulusMatrix = stimMat,
nSlope = threshSlope)
# Update task performance
X_g <- updateTaskPerformance(P_sub_g    = P_g,
TaskMat    = X_g,
QuitProb   = quitP)
# Capture current task performance tally
tally <- matrix(c(t, colSums(X_g)), ncol = ncol(X_g) + 1)
colnames(tally) <- c("t", colnames(X_g))
tally <- transform(tally, Inactive = n - sum(X_g), n = n, replicate = sim)
taskTally[[t]] <- tally
# Update total task performance profile
X_tot <- X_tot + X_g
# Create time step for correlation
if (t %% corrStep == 0) {
# Get tasks performance in correlation step
X_step <- X_tot - X_prevTot
# Add to ensemble list of task steps
taskStep[[t / corrStep]] <- X_step
# Calculate rank correlation if it is not the first step
if(sum(X_prev) != 0) {
# Normalize
stepNorm <- X_step / rowSums(X_step)
prevNorm <- X_prev / rowSums(X_prev)
# Calculate ranks
step_ranks <- calculateTaskRank(TaskStepMat = X_step)
prev_ranks <- calculateTaskRank(TaskStepMat = X_prev)
# Calculate Correlation
rankCorr <- cor(prev_ranks, step_ranks, method = "spearman")
# Put in list
corr <- diag(rankCorr)
corr <- as.data.frame(corr)
corr <- t(corr)
corr$timestep <- t
corr$n <- n
corr$replicate <- sim
names(corr)[1:2] <- c("Task1", "Task2")
taskCorr <- rbind(taskCorr, corr)
}
# Update previous step total matrix
X_prevTot <- X_tot
# Update previous step total matrix
X_prev <- X_step
}
}
# Calculate Entropy
entropy <- mutualEntropy(TotalStateMat = X_tot)
entropy <- transform(entropy, n = n, replicate = sim)
# Calculate total task distribution
# totalTaskDist <- X_tot / rowSums(X_tot)
totalTaskDist <- X_tot / gens
totalTaskDist <- transform(totalTaskDist, Inactive = gens - rowSums(X_tot), n = n, replicate = sim)
# Create tasktally table
taskTally <- do.call("rbind", taskTally)
# Create tasktally table
stimMat <- transform(stimMat, n = n, replicate = sim)
# Add total task distributions, entropy values, and graphs to lists
ens_taskDist[[sim]]  <- totalTaskDist
ens_entropy[[sim]]   <- entropy
ens_taskCorr[[sim]]  <- taskCorr
ens_taskTally[[sim]] <- taskTally
ens_taskStep[[sim]]  <- taskStep
ens_stim[[sim]]      <- stimMat
# Print simulation completed
print(paste0("DONE: N = ", n, ", Simulation ", sim))
}
# Unlist for corr over time
runCorrs <- do.call("rbind", ens_taskCorr)
# Add to list of lists
groups_taskDist[[i]]  <- ens_taskDist
groups_taskCorr[[i]]  <- runCorrs
groups_taskStep[[i]]  <- ens_taskStep
groups_taskTally[[i]] <- ens_taskTally
groups_stim[[i]]      <- ens_stim
groups_entropy[[i]]   <- ens_entropy
}
# trim out correlations for group size 1
if(1 %in% Ns) {
groups_taskCorr <- groups_taskCorr[-1]
}
corrSum <- Corrs %>%
group_by(n, Set) %>%
summarise(MeanSpec = mean(Specialization, na.rm = TRUE))
# Plot - Corr over time
Corrs <- do.call("rbind", groups_taskCorr)
Corrs <- Corrs %>%
mutate(Set = paste(n, replicate, sep = "-")) %>%
rowwise() %>%
mutate(Specialization = mean(c(Task1, Task2), na.rm = TRUE))
sigma <- ThreshSD / ThreshM
gg_corrtime <- ggplot(data = Corrs,
aes(x = timestep, y = Specialization, group = Set, col = as.factor(n))) +
geom_hline(data = Corrs,
aes(yintercept = 0),
colour = "grey30",
alpha = 0.5) +
geom_line(alpha = 0.6) +
theme_classic() +
scale_y_continuous(limits = c(-1, 1), breaks = seq(-1, 1, 0.5)) +
scale_colour_manual(values = c("#F00924", "#4C0E78")) +
xlab("Timestep") +
facet_grid(replicate ~ n) +
ggtitle(paste("Fixed Thresholds, Sigma =", sigma[1])) +
theme(legend.position = "none",
axis.text = element_text(size = 6))
gg_corrtime
gg_corrtime <- ggplot(data = Corrs,
aes(x = timestep, y = Specialization, group = Set, col = as.factor(n))) +
geom_hline(data = Corrs,
aes(yintercept = 0),
colour = "grey30",
alpha = 0.5) +
geom_line(alpha = 0.6) +
theme_classic() +
scale_y_continuous(limits = c(-1, 1), breaks = seq(-1, 1, 0.5)) +
# scale_colour_manual(values = c("#F00924", "#4C0E78")) +
xlab("Timestep") +
facet_grid(replicate ~ n) +
ggtitle(paste("Fixed Thresholds, Sigma =", sigma[1])) +
theme(legend.position = "none",
axis.text = element_text(size = 6))
gg_corrtime
save(groups_entropy, groups_stim, groups_taskCorr, groups_taskDist, groups_taskStep, groups_taskTally, taskCorrTot, file = "output/FitnessPlots/Rdata/Eta7Sigma01_20reps.Rdata")
save(groups_entropy, groups_stim, groups_taskCorr, groups_taskDist, groups_taskStep, groups_taskTally, file = "output/FitnessPlots/Rdata/Eta7Sigma01_20reps.Rdata")
rm(list = ls())
source("scripts/__Util__MASTER.R")
source("scripts/3A_PrepPlotExperimentData.R")
library(RColorBrewer)
library(scales)
load("output/SpecializationMetrics/Rdata/Fixed_Delta06Sigma01Eta7LargerGroups100reps.Rdata")
####################
load("output/SpecializationMetrics/Rdata/Fixed_Delta06Sigma01Eta7LargerGroups100reps.Rdata")
##############
# Parameter Space Exploration
####################
rm(list = ls())
source("scripts/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
# load
load("output/ParameterExploration/Rdata/FixedDelta06_SigmaSlopeExploration.Rdata")
# Plot - Corr over time
Corrs <- do.call("rbind", groups_taskCorr)
Corrs <- Corrs %>%
mutate(Set = paste(n, replicate, sep = "-")) %>%
rowwise() %>%
mutate(Specialization = mean(c(Task1, Task2), na.rm = TRUE))
sigma <- ThreshSD / ThreshM
gg_corrtime <- ggplot(data = Corrs,
aes(x = timestep, y = Specialization, group = Set, col = as.factor(n))) +
geom_hline(data = Corrs,
aes(yintercept = 0),
colour = "grey30",
alpha = 0.5) +
geom_line(alpha = 0.6) +
theme_classic() +
scale_y_continuous(limits = c(-1, 1), breaks = seq(-1, 1, 0.5)) +
# scale_colour_manual(values = c("#F00924", "#4C0E78")) +
xlab("Timestep") +
facet_grid(replicate ~ n) +
ggtitle(paste("Fixed Thresholds, Sigma =", sigma[1])) +
theme(legend.position = "none",
axis.text = element_text(size = 6))
gg_corrtime
Corrs <- do.call("rbind", groups_taskCorr)
load("output/ParameterExploration/Rdata/FixedDelta06_SigmaSlopeExploration.Rdata")
rm(list = ls())
source("scripts/__Util__MASTER.R")
source("scripts/3A_PrepPlotExperimentData.R")
load("output/__RData/FixedDelta06Sigma01Eta7100reps.Rdata")
Corrs <- do.call("rbind", groups_taskCorr)
Corrs <- Corrs %>%
mutate(Set = paste(n, replicate, sep = "-")) %>%
rowwise() %>%
mutate(Specialization = mean(c(Task1, Task2), na.rm = TRUE))
sigma <- ThreshSD / ThreshM
ThreshSD       <- ThreshM * 0.1 #population threshold standard deviations !!Change!!
ThreshM        <- c(10, 10) #population threshold means
ThreshSD       <- ThreshM * 0.1 #population threshold standard deviations !!Change!!
sigma <- ThreshSD / ThreshM
gg_corrtime <- ggplot(data = Corrs,
aes(x = timestep, y = Specialization, group = Set, col = as.factor(n))) +
geom_hline(data = Corrs,
aes(yintercept = 0),
colour = "grey30",
alpha = 0.5) +
geom_line(alpha = 0.6) +
theme_classic() +
scale_y_continuous(limits = c(-1, 1), breaks = seq(-1, 1, 0.5)) +
# scale_colour_manual(values = c("#F00924", "#4C0E78")) +
xlab("Timestep") +
facet_grid(replicate ~ n) +
ggtitle(paste("Fixed Thresholds, Sigma =", sigma[1])) +
theme(legend.position = "none",
axis.text = element_text(size = 6))
gg_corrtime
View(Corrs)
####################
# Parameter Space Exploration
####################
rm(list = ls())
source("scripts/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
# load
load("output/ParameterExploration/Rdata/FixedDelta06_SigmaSlopeExploration.Rdata")
improve <- improve %>%
mutate(relativePercInc = (PercIncrease - 1.220554) / 1.220554,
relativeSlope   = (SlopeIncrease - 0.02322321) / 0.02322321,
relativeLarge   = (SpecLarge - 0.5915000) / 0.5915000,
relativeSmall   = (SpecSmall - 0.2663750) / 0.2663750,
Increase        = SlopeIncrease * 14) %>%
mutate(fit = (abs(relativeLarge) + abs(relativeSmall) + abs(relativeSlope)) / 3)
rm(list = ls())
source("scripts/__Util__MASTER.R")
library(RColorBrewer)
library(scales)
library(ggthemes)
# Load and prep experimental data
source("scripts/3A_PrepPlotExperimentData.R")
yukoCorr <- yukoCorr %>%
mutate(Sigma = NA)
# Load and prep fixed probabilistic sigma = 0.1
load("output/__RData/FixedDelta06Sigma01Eta7100reps.Rdata")
taskCorrTot <- do.call("rbind", groups_taskCorr)
fixedprob_01 <-  taskCorrTot %>%
mutate(TaskMean = (Task1 + Task2) / 2) %>%
mutate(Sigma = 0.1,
Source = "Model") %>%
select(n, TaskMean, Source, Sigma)
# Load and prep fixed probabilistic sigma = 0.25
load("output/__RData/Fixed_Delta06Sigma025Eta7.Rdata")
taskCorrTot <- do.call("rbind", groups_taskCorr)
fixedprob_025 <-  taskCorrTot %>%
mutate(TaskMean = (Task1 + Task2) / 2) %>%
mutate(Sigma = 0.25,
Source = "Model") %>%
select(n, TaskMean, Source, Sigma)
# Load and prep fixed probabilistic sigma = 0.05
load("output/__RData/Fixed_Delta06Sigma005Eta7.Rdata")
taskCorrTot <- do.call("rbind", groups_taskCorr)
fixedprob_005 <-  taskCorrTot %>%
mutate(TaskMean = (Task1 + Task2) / 2) %>%
mutate(Sigma = 0.05,
Source = "Model") %>%
select(n, TaskMean, Source, Sigma)
# Load and prep fixed probabilistic sigma = 0.3, eta = 2
load("output/__RData/Fixed_Delta06Sigma03.Rdata")
taskCorrTot <- do.call("rbind", groups_taskCorr)
fixedprob_03 <-  taskCorrTot %>%
mutate(TaskMean = (Task1 + Task2) / 2) %>%
mutate(Sigma = 0.3,
Source = "Model") %>%
select(n, TaskMean, Source, Sigma)
# Bind into large dataframe
allFixedProbCorr <- fixedprob_01 %>%
rbind(fixedprob_005) %>%
rbind(fixedprob_025) %>%
rbind(fixedprob_03) %>%
rbind(yukoCorr) %>%
mutate(Source = as.factor(Source)) %>%
group_by(Source, n, Sigma) %>%
summarise(SpecMean = mean(TaskMean),
SpecSE = sd(TaskMean) / sqrt(length(TaskMean)),
SpecCI = 1.96 * SpecSE) %>%
mutate(Set = paste0(Source, Sigma)) %>%
mutate(Set = factor(Set, levels = c("ExperimentNA", "Model0.05", "Model0.1", "Model0.25", "Model0.3")))
# Set pallete
fixedProbpalette <- c("grey45", "#FFB84F", "#E81715", "#F55632", "#FD792C")
fillPalette <- c("#ffffff","#FFB84F", "#E81715", "#F55632", "#FD792C")
# Plot with experimental data
gg_fixedProb <- ggplot(data = allFixedProbCorr) +
theme_classic() +
labs(x = "Group Size",
y = "Specialization") +
scale_x_continuous(breaks = unique(taskCorrTot$n)) +
scale_y_continuous(breaks = seq(-1, 1, 0.1),
limits = c(0, 0.9)) +
scale_colour_manual(values = fixedProbpalette,
labels = c("Experiment",
expression(paste(sigma, " = 0.05, ", eta, " = 7")),
expression(paste(sigma, " = 0.1, ", eta, " = 7")),
expression(paste(sigma, " = 0.25, ", eta, " = 7")),
expression(paste(sigma, " = 0.3, ", eta, " = 2")))) +
scale_fill_manual(values = fillPalette,
labels = c("Experiment",
expression(paste(sigma, " = 0.05, ", eta, " = 7")),
expression(paste(sigma, " = 0.1, ", eta, " = 7")),
expression(paste(sigma, " = 0.25, ", eta, " = 7")),
expression(paste(sigma, " = 0.3, ", eta, " = 2")))) +
scale_shape_manual(values = c(21, 22, 21, 25, 24),
labels = c("Experiment",
expression(paste(sigma, " = 0.05, ", eta, " = 7")),
expression(paste(sigma, " = 0.1, ", eta, " = 7")),
expression(paste(sigma, " = 0.25, ", eta, " = 7")),
expression(paste(sigma, " = 0.3, ", eta, " = 2")))) +
# Mean and SE portion of plot
geom_errorbar(aes(x = n, ymin = SpecMean - SpecSE, ymax = SpecMean + SpecSE, colour = Set, width = 1.5),
position = position_dodge(width = 0.5),
size = 0.25) +
geom_line(aes(x = n, y = SpecMean,  colour = Set),
size = 0.3,
position = position_dodge(width = 0.5)) +
geom_point(aes(x = n, y = SpecMean, colour = Set, fill = Set, shape = Set),
position = position_dodge(width = 0.5),
size = 1.5) +
theme(legend.position = "none",
legend.justification = c(1, 1),
legend.title = element_blank(),
legend.key.height = unit(0.3, "cm"),
legend.key.width= unit(0.4, "cm"),
legend.margin =  margin(t = 0, r = 0, b = 0, l = -0.2, "cm"),
legend.text = element_text(size = 6),
legend.text.align = 0,
# legend.box.background = element_rect(),
axis.text.y = element_text(size = 6, margin = margin(5, 6, 5, -2)),
axis.text.x = element_text(size = 6, margin = margin(6, 5, -2, 5)),
axis.title = element_text(size = 6, margin = margin(0, 0, 0, 0)),
axis.ticks.length = unit(-0.1, "cm"))
gg_fixedProb
svg("output/MSFigures/FixedProbSpecializationFits.svg", width = 2.65, height = 2.05)
gg_fixedProb
dev.off()
svg("output/MSFigures/FixedProbSpecializationFits.svg", width = 2.7, height = 2.05)
gg_fixedProb
dev.off()
svg("output/MSFigures/FixedProbSpecializationFits.svg", width = 2.75, height = 2.05)
gg_fixedProb
dev.off()
svg("output/MSFigures/FixedProbSpecializationFits.svg", width = 2.71, height = 2.05)
gg_fixedProb
dev.off()
