#   xlab("Group size") +
#   ylab("Behavioral Variation (SD)") +
#   scale_x_continuous(breaks = unique(taskVarMean$n)) +
#   scale_y_continuous(breaks = seq(0, 1, 0.025)) +
#   # Mean and SE portion of plot
#   geom_errorbar(data = taskVarMeans,
#                 aes(x = n, ymin = SDMean - SDSE, ymax = SDMean + SDSE, colour = Source, width = 1.5),
#                 position = position_dodge(width = 1)) +
#   geom_point(data = taskVarMeans,
#              aes(x = n, y = SDMean, colour = Source),
#              size = 2,
#              position = position_dodge(width = 1)) +
#   geom_line(data = taskVarMeans,
#             aes(x = n, y = SDMean, colour = Source),
#             position = position_dodge(width = 1)) +
#   scale_fill_manual(values = compPalette) +
#   scale_colour_manual(values = compPalette) +
#   theme(legend.position = "none",
#         axis.text = element_text(size = 8),
#         axis.title = element_text(size = 10))
gg_varNorm <- ggplot() +
geom_hline(data = taskVarMean,
aes(yintercept = 1),
colour = "grey30") +
geom_point(data = taskVarMean,
aes(x = n, y = NormVarMean, colour = Source),
size = 0.8,
alpha = 0.4,
position = position_dodge(width = 1)) +
theme_classic() +
xlab("Group size") +
ylab("Relative behavioral variation") +
scale_x_continuous(breaks = unique(taskVarMean$n)) +
scale_y_continuous(breaks = seq(0, 3, 0.5)) +
# Mean and SE portion of plot
geom_errorbar(data = taskVarMeans,
aes(x = n, ymin = NormVarMean - NormVarMeanSE, ymax = NormVarMean + NormVarMeanSE, colour = Source, width = 1.5),
position = position_dodge(width = 1)) +
geom_point(data = taskVarMeans,
aes(x = n, y = NormVarMean, colour = Source),
size = 2,
position = position_dodge(width = 1)) +
geom_line(data = taskVarMeans,
aes(x = n, y = NormVarMean, colour = Source),
position = position_dodge(width = 1)) +
scale_fill_manual(values = compPalette) +
scale_colour_manual(values = compPalette) +
theme(legend.position = "none",
axis.text = element_text(size = 8),
axis.title = element_text(size = 10, margin = margin(0, 0, 0, 0)))
gg_varNorm
source("scripts/3A_PrepPlotExperimentData.R")
# Bind together
taskDist <- unlist(groups_taskDist, recursive = FALSE)
taskDistTot <- do.call("rbind", taskDist)
# Manipulate
taskDistTot <- taskDistTot %>%
mutate(set = paste0(n, "-", replicate)) %>%
mutate(set = factor(set,
levels = mixedsort(unique(set))),
n = as.factor(n))
taskSum <- taskDistTot %>%
group_by(n) %>%
summarise(taskMean1 = mean(Task1),
taskMean2 = mean(Task2))
# Plot
plot_TaskMat <- as.data.frame(taskDistTot)
gg_dist <- ggplot(data = plot_TaskMat, aes(y = Task1, x = set)) +
geom_point(aes(colour = n), size = 0.3) +
theme_classic() +
labs(x = "Group size",
y = "Task 1 frequency") +
scale_color_manual(values = palette) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
theme(axis.text.x = element_text(size = 0),
axis.ticks.x = element_blank(),
axis.text = element_text(size = 8),
axis.title.y = element_text(size = 10, margin = margin(0, 0, 0, 0)),
axis.title.x = element_text(size = 10, margin = margin(12, 0, 0, 0)),
legend.position = "none")
gg_dist
rm(list = ls())
source("scripts/__Util__MASTER.R")
####################
# Set global variables
####################
# Initial paramters: Free to change
# Base parameters
Ns             <- c(1, 2, 4, 6, 8, 12, 16) #vector of number of individuals to simulate
m              <- 2 #number of tasks
gens           <- 10000 #number of generations to run simulation
corrStep       <- 200 #number of time steps for calculation of correlation
reps           <- 15 #number of replications per simulation (for ensemble) !!Change!!
# Threshold Parameters
ThreshM        <- c(100, 100) #population threshold means
ThreshSD       <- ThreshM * 0.1 #population threshold standard deviations !!Change!!
InitialStim    <- c(0, 0) #intital vector of stimuli
StimRates      <- c(0.6, 0.6) #vector of stimuli increase rates
threshSlope    <- 7 #exponent parameter for threshold curve shape
alpha          <- m #efficiency of task performance
quitP          <- 0.2 #probability of quitting task once active
# Social Network Parameters
p              <- 0 #probability of interacting with individual in other states
q              <- 1 #probability of interacting with individual in same state relative to others
####################
# Run simulation multiple times
####################
# Prep meta-lists for collection of group size simulations
groups_taskDist  <- list()
groups_taskCorr  <- list()
groups_taskStep  <- list()
groups_taskTally <- list()
groups_stim      <- list()
groups_entropy   <- list()
# Loop through group sizes
for (i in 1:length(Ns)) {
# Set group size
n <- Ns[i]
# Prep lists for collection of simulation outputs
ens_taskDist  <- list()
ens_taskCorr  <- list()
ens_taskStep  <- list()
ens_taskTally <- list()
ens_entropy   <- list()
ens_stim      <- list()
# Run Simulations
for (sim in 1:reps) {
####################
# Seed structures and intial matrices
####################
# Set initial probability matrix (P_g)
P_g <- initiateProbMatrix(n = n, m = m)
# Seed task (external) stimuli
stimMat <- seedStimuls(InitialSVector = InitialStim,
RateVector = StimRates,
gens = gens)
# Seed internal thresholds
threshMat <- seedThresholds(n = n,
m = m,
ThresholdMeans = ThreshM,
ThresholdSDs = ThreshSD)
# Start task performance
X_g <- matrix(data = rep(0, length(P_g)), ncol = ncol(P_g))
# Create cumulative task performance matrix
X_tot <- X_g
# Prep correlation step matrix
X_prev <- matrix(data = rep(0, n * m), ncol = m)
X_prevTot <- matrix(data = rep(0, n * m), ncol = m)
taskCorr <- list()
taskStep <- list()
taskTally <- list()
####################
# Simulate
####################
# Run simulation
for (t in 1:gens) {
# Update stimuli
for (j in 1:(ncol(stimMat)/2)) {
# update stim
stimMat[t + 1, j] <- globalStimUpdate(stimulus = stimMat[t, j],
delta = stimMat[t, j + m],
alpha = alpha,
Ni = sum(X_g[ , j]),
n = n)
# shift down delta (rate increases)
stimMat[t + 1, j + m] <- stimMat[t, j + m]
}
# Update social network
# g_adj <- temporalNetwork(X_sub_g = X_g,
#                          p = p,
#                          bias = q)
# Calculate task demand based on global stimuli
P_g <- calcThresholdProbMat(TimeStep = t + 1, # first row is generation 0
ThresholdMatrix = threshMat,
StimulusMatrix = stimMat,
nSlope = threshSlope)
# Update task performance
X_g <- updateTaskPerformance(P_sub_g    = P_g,
TaskMat    = X_g,
QuitProb   = quitP)
# Capture current task performance tally
tally <- matrix(c(t, colSums(X_g)), ncol = ncol(X_g) + 1)
colnames(tally) <- c("t", colnames(X_g))
tally <- transform(tally, Inactive = n - sum(X_g), n = n, replicate = sim)
taskTally[[t]] <- tally
# Update total task performance profile
X_tot <- X_tot + X_g
# Create time step for correlation
if (t %% corrStep == 0) {
# Get tasks performance in correlation step
X_step <- X_tot - X_prevTot
# Add to ensemble list of task steps
taskStep[[t / corrStep]] <- X_step
# Calculate rank correlation if it is not the first step
if(sum(X_prev) != 0) {
# Normalize
stepNorm <- X_step / rowSums(X_step)
prevNorm <- X_prev / rowSums(X_prev)
# Calculate ranks
step_ranks <- calculateTaskRank(TaskStepMat = X_step)
prev_ranks <- calculateTaskRank(TaskStepMat = X_prev)
# Calculate Correlation
rankCorr <- cor(prev_ranks, step_ranks, method = "spearman")
# Put in list
taskCorr[[(t / corrStep) - 1]] <- diag(rankCorr)
names(taskCorr)[(t / corrStep) - 1] <- paste0("Gen", t)
}
# Update previous step total matrix
X_prevTot <- X_tot
# Update previous step total matrix
X_prev <- X_step
}
}
# Calculate Entropy
entropy <- mutualEntropy(TotalStateMat = X_tot)
entropy <- transform(entropy, n = n, replicate = sim)
# Calculate total task distribution
# totalTaskDist <- X_tot / rowSums(X_tot)
totalTaskDist <- X_tot / gens
totalTaskDist <- transform(totalTaskDist, Inactive = gens - rowSums(X_tot), n = n, replicate = sim)
# Create tasktally table
taskTally <- do.call("rbind", taskTally)
# Create tasktally table
stimMat <- transform(stimMat, n = n, replicate = sim)
# Add total task distributions, entropy values, and graphs to lists
ens_taskDist[[sim]]  <- totalTaskDist
ens_entropy[[sim]]   <- entropy
ens_taskCorr[[sim]]  <- taskCorr
ens_taskTally[[sim]] <- taskTally
ens_taskStep[[sim]]  <- taskStep
ens_stim[[sim]]      <- stimMat
# Print simulation completed
print(paste0("DONE: N = ", n, ", Simulation ", sim))
}
# Calculate mean correlation for each n
runCorrs <- lapply(ens_taskCorr, function(x) {
# Unlist
runs <- do.call("rbind", x)
# Calculate mean
runMean <- matrix(data = rep(NA, m), ncol =  m)
for (column in 1:m) {
runMean[ , column] <- mean(runs[ , column], na.rm = TRUE)
}
colnames(runMean) <- colnames(runs)
return(runMean)
})
runCorrs <- do.call("rbind", runCorrs)
runCorrs <- transform(runCorrs, n = n)
# Add to list of lists
groups_taskDist[[i]]  <- ens_taskDist
groups_taskCorr[[i]]  <- runCorrs
groups_taskStep[[i]]  <- ens_taskStep
groups_taskTally[[i]] <- ens_taskTally
groups_stim[[i]]      <- ens_stim
groups_entropy[[i]]   <- ens_entropy
}
# trim out correlations for group size 1
if(1 %in% Ns) {
groups_taskCorr <- groups_taskCorr[-1]
}
# Bind together
taskDist <- unlist(groups_taskDist, recursive = FALSE)
taskDistTot <- do.call("rbind", taskDist)
# Manipulate
taskDistTot <- taskDistTot %>%
mutate(set = paste0(n, "-", replicate)) %>%
mutate(set = factor(set,
levels = mixedsort(unique(set))),
n = as.factor(n))
taskSum <- taskDistTot %>%
group_by(n) %>%
summarise(taskMean1 = mean(Task1),
taskMean2 = mean(Task2))
# Plot
plot_TaskMat <- as.data.frame(taskDistTot)
gg_dist <- ggplot(data = plot_TaskMat, aes(y = Task1, x = set)) +
geom_point(aes(colour = n), size = 0.3) +
theme_classic() +
labs(x = "Group size",
y = "Task 1 frequency") +
scale_color_manual(values = palette) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
theme(axis.text.x = element_text(size = 0),
axis.ticks.x = element_blank(),
axis.text = element_text(size = 8),
axis.title.y = element_text(size = 10, margin = margin(0, 0, 0, 0)),
axis.title.x = element_text(size = 10, margin = margin(12, 0, 0, 0)),
legend.position = "none")
gg_dist
source("scripts/3A_PrepPlotExperimentData.R")
# Set variable
filename <- "Fixed_Delta06Sigma01Eta7"
# Palette without single individuals
#palette <- c("#F00924", "#F7A329", "#FDD545", "#027C2C", "#1D10F9", "#4C0E78", "#bdbdbd", "#525252")
# Palette without single individuals
palette <- c("#83343E", "#F00924", "#F7A329", "#FDD545", "#027C2C", "#1D10F9", "#4C0E78", "#bdbdbd", "#525252")
# Model vs Data Palette
compPalette <- c("indianred2", "black")
####################
# Final task distributions
####################
# Bind together
taskDist <- unlist(groups_taskDist, recursive = FALSE)
taskDistTot <- do.call("rbind", taskDist)
# Manipulate
taskDistTot <- taskDistTot %>%
mutate(set = paste0(n, "-", replicate)) %>%
mutate(set = factor(set,
levels = mixedsort(unique(set))),
n = as.factor(n))
taskSum <- taskDistTot %>%
group_by(n) %>%
summarise(taskMean1 = mean(Task1),
taskMean2 = mean(Task2))
# Plot
plot_TaskMat <- as.data.frame(taskDistTot)
gg_dist <- ggplot(data = plot_TaskMat, aes(y = Task1, x = set)) +
geom_point(aes(colour = n), size = 0.3) +
theme_classic() +
labs(x = "Group size",
y = "Task 1 frequency") +
scale_color_manual(values = palette) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
theme(axis.text.x = element_text(size = 0),
axis.ticks.x = element_blank(),
axis.text = element_text(size = 8),
axis.title.y = element_text(size = 10, margin = margin(0, 0, 0, 0)),
axis.title.x = element_text(size = 10, margin = margin(12, 0, 0, 0)),
legend.position = "none")
gg_dist
# Prep
taskVarMean <- taskDistTot %>%
mutate(n = as.character(n)) %>%
mutate(n = as.numeric(n)) %>%
group_by(n, replicate) %>%
summarise(SD1 = sd(Task1),
SD2 = sd(Task2),
Mean = mean(Task1)) %>%
mutate(Source = "Model",
SD = (SD1 + SD2) / 2)
taskVarMean$SD[is.na(taskVarMean$SD)] <- 0 #fix for single individuals
taskVarMean <- rbind(taskVarMean, yukoDataSummary)
# Calculate means and SE
taskVarMeans <- taskVarMean %>%
group_by(n, Source) %>%
summarise(MeanMean = mean(Mean),
MeanSE = sd(Mean) / sqrt(length(Mean)),
SDMean = mean(SD),
SDSE = sd(SD) / sqrt(length(SD)))
# Get mean at group size one and normalize
expSizeOne <- taskVarMeans$MeanMean[taskVarMeans$n == 1 & taskVarMeans$Source == "Experiment"]
modSizeOne <- taskVarMeans$MeanMean[taskVarMeans$n == 1 & taskVarMeans$Source == "Model"]
expSizeSixteen <- taskVarMeans$SDMean[taskVarMeans$n == 16 & taskVarMeans$Source == "Experiment"]
modSizeSixteen <- taskVarMeans$SDMean[taskVarMeans$n == 16 & taskVarMeans$Source == "Model"]
# Normalize Mean Values
taskVarMeans$NormMean <- NA
taskVarMeans$NormMeanSE <- NA
taskVarMeans$NormMean[taskVarMeans$Source == "Experiment"] <- taskVarMeans$MeanMean[taskVarMeans$Source == "Experiment"] / expSizeOne
taskVarMeans$NormMean[taskVarMeans$Source == "Model"] <- taskVarMeans$MeanMean[taskVarMeans$Source == "Model"] / modSizeOne
taskVarMeans$NormMeanSE[taskVarMeans$Source == "Experiment"] <- taskVarMeans$MeanSE[taskVarMeans$Source == "Experiment"] / expSizeOne
taskVarMeans$NormMeanSE[taskVarMeans$Source == "Model"] <- taskVarMeans$MeanSE[taskVarMeans$Source == "Model"] / modSizeOne
taskVarMean$NormMean <- NA
taskVarMean$NormMean[taskVarMean$Source == "Experiment"] <- taskVarMean$Mean[taskVarMean$Source == "Experiment"] / expSizeOne
taskVarMean$NormMean[taskVarMean$Source == "Model"] <- taskVarMean$Mean[taskVarMean$Source == "Model"] / modSizeOne
# Normalize behavioral variation values
taskVarMeans$NormVarMean <- NA
taskVarMeans$NormVarMeanSE <- NA
taskVarMeans$NormVarMean[taskVarMeans$Source == "Experiment"] <- taskVarMeans$SDMean[taskVarMeans$Source == "Experiment"] / expSizeSixteen
taskVarMeans$NormVarMean[taskVarMeans$Source == "Model"] <- taskVarMeans$SDMean[taskVarMeans$Source == "Model"] / modSizeSixteen
taskVarMeans$NormVarMeanSE[taskVarMeans$Source == "Experiment"] <- taskVarMeans$SDSE[taskVarMeans$Source == "Experiment"] / expSizeSixteen
taskVarMeans$NormVarMeanSE[taskVarMeans$Source == "Model"] <- taskVarMeans$SDSE[taskVarMeans$Source == "Model"] / modSizeSixteen
taskVarMean$NormVarMean <- NA
taskVarMean$NormVarMean[taskVarMean$Source == "Experiment"] <- taskVarMean$SD[taskVarMean$Source == "Experiment"] / expSizeSixteen
taskVarMean$NormVarMean[taskVarMean$Source == "Model"] <- taskVarMean$SD[taskVarMean$Source == "Model"] / modSizeSixteen
# Plot variance and mean by group size
# gg_var <- ggplot() +
#   geom_point(data = taskVarMean,
#              aes(x = n, y = SD, colour = Source),
#              size = 0.5,
#              alpha = 0.4,
#              position = position_dodge(width = 1)) +
#   theme_classic() +
#   xlab("Group size") +
#   ylab("Behavioral Variation (SD)") +
#   scale_x_continuous(breaks = unique(taskVarMean$n)) +
#   scale_y_continuous(breaks = seq(0, 1, 0.025)) +
#   # Mean and SE portion of plot
#   geom_errorbar(data = taskVarMeans,
#                 aes(x = n, ymin = SDMean - SDSE, ymax = SDMean + SDSE, colour = Source, width = 1.5),
#                 position = position_dodge(width = 1)) +
#   geom_point(data = taskVarMeans,
#              aes(x = n, y = SDMean, colour = Source),
#              size = 2,
#              position = position_dodge(width = 1)) +
#   geom_line(data = taskVarMeans,
#             aes(x = n, y = SDMean, colour = Source),
#             position = position_dodge(width = 1)) +
#   scale_fill_manual(values = compPalette) +
#   scale_colour_manual(values = compPalette) +
#   theme(legend.position = "none",
#         axis.text = element_text(size = 8),
#         axis.title = element_text(size = 10))
gg_varNorm <- ggplot() +
geom_hline(data = taskVarMean,
aes(yintercept = 1),
colour = "grey30") +
geom_point(data = taskVarMean,
aes(x = n, y = NormVarMean, colour = Source),
size = 0.8,
alpha = 0.4,
position = position_dodge(width = 1)) +
theme_classic() +
xlab("Group size") +
ylab("Relative behavioral variation") +
scale_x_continuous(breaks = unique(taskVarMean$n)) +
scale_y_continuous(breaks = seq(0, 3, 0.5)) +
# Mean and SE portion of plot
geom_errorbar(data = taskVarMeans,
aes(x = n, ymin = NormVarMean - NormVarMeanSE, ymax = NormVarMean + NormVarMeanSE, colour = Source, width = 1.5),
position = position_dodge(width = 1)) +
geom_point(data = taskVarMeans,
aes(x = n, y = NormVarMean, colour = Source),
size = 2,
position = position_dodge(width = 1)) +
geom_line(data = taskVarMeans,
aes(x = n, y = NormVarMean, colour = Source),
position = position_dodge(width = 1)) +
scale_fill_manual(values = compPalette) +
scale_colour_manual(values = compPalette) +
theme(legend.position = "none",
axis.text = element_text(size = 8),
axis.title = element_text(size = 10, margin = margin(0, 0, 0, 0)))
gg_varNorm
gg_mean <- ggplot() +
geom_hline(data = taskVarMean,
aes(yintercept = 1),
colour = "grey30") +
geom_point(data = taskVarMean,
aes(x = n, y = NormMean, colour = Source),
size = 0.5,
alpha = 0.4,
position = position_dodge(width = 1)) +
theme_classic() +
xlab("Group size") +
ylab("Relative task 1 frequency") +
scale_x_continuous(breaks = unique(taskVarMean$n)) +
scale_y_continuous(breaks = seq(0, 1.5, 0.05)) +
# Mean and SE portion of plot
geom_errorbar(data = taskVarMeans,
aes(x = n, ymin = NormMean - NormMeanSE, ymax = NormMean + NormMeanSE, colour = Source, width = 1.5),
position = position_dodge(width = 1)) +
geom_point(data = taskVarMeans,
aes(x = n, y = NormMean, colour = Source),
size = 2,
position = position_dodge(width = 1)) +
geom_line(data = taskVarMeans,
aes(x = n, y = NormMean, colour = Source),
position = position_dodge(width = 1)) +
scale_fill_manual(values = compPalette) +
scale_colour_manual(values = compPalette) +
theme(legend.position = "none",
axis.text = element_text(size = 8),
axis.title = element_text(size = 10, margin = margin(0, 0, 0, 0)))
gg_mean
# Unlist
taskCorrTot <- do.call("rbind", groups_taskCorr)
taskCorrTot <- taskCorrTot %>%
mutate(TaskMean = (Task1 + Task2) / 2)
# Manipulate and bind with Yuko data
taskCorrTot <- taskCorrTot %>%
mutate(Source = "Model") %>%
select(n, TaskMean, Source) %>%
rbind(yukoCorr) %>%
mutate(Source = as.factor(Source))
# Calculate means and SE
taskCorrMeans <- taskCorrTot %>%
group_by(Source, n) %>%
summarise(SpecMean = mean(TaskMean),
SpecSE = sd(TaskMean) / sqrt(length(TaskMean)),
SpecCI = 1.96 * SpecSE)
# Plot
gg_corr <- ggplot() +
geom_hline(data = taskCorrTot,
aes(yintercept = 0),
colour = "grey30") +
geom_point(data = taskCorrTot,
aes(x = n, y = TaskMean, fill = Source, colour = Source),
size = 0.5,
position = position_dodge(width = 1),
alpha = 0.4) +
theme_classic() +
labs(x = "Group size",
y = "Specialization") +
scale_x_continuous(breaks = unique(taskCorrTot$n)) +
scale_y_continuous(breaks = seq(-1, 1, 0.2)) +
scale_fill_manual(values = compPalette) +
scale_colour_manual(values = compPalette) +
theme(legend.position = "none",
axis.text = element_text(size = 8),
axis.title = element_text(size = 10, margin = margin(0, 0, 0, 0))) +
# Mean and SE portion of plot
geom_errorbar(data = taskCorrMeans,
aes(x = n, ymin = SpecMean - SpecSE, ymax = SpecMean + SpecSE, colour = Source, width = 1.5),
position = position_dodge(width = 1)) +
geom_point(data = taskCorrMeans,
aes(x = n, y = SpecMean, colour = Source, fill = Source),
position = position_dodge(width = 1),
size = 2) +
geom_line(data = taskCorrMeans,
aes(x = n, y = SpecMean,  colour = Source),
position = position_dodge(width = 1))
gg_corr
